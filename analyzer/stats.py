import math
import os

import numpy as np

import matplotlib
import matplotlib.pyplot as plt
import pandas as pd
from analyzer import LOGGER
from scipy.stats import chi2, norm

NEUTRAL = 0
POSITIVE = 1
NEGATIVE = -1

ALPHA_LEVEL = 0.05
MARGIN_OF_ERROR = 0.01


def read_predictions(filepath: str):
    """Reads a predictions csv file generated by Senti4SD
    and returns a pandas dataframe of the predictions."""
    data = pd.read_csv(filepath).drop(['Row'], axis=1)
    data.loc[data.Predicted == 'negative', 'Predicted'] = NEGATIVE
    data.loc[data.Predicted == 'positive', 'Predicted'] = POSITIVE
    data.loc[data.Predicted == 'neutral', 'Predicted'] = NEUTRAL
    return data


def generate_dfname_from_filename(filename: str):
    return os.path.splitext(os.path.basename(filename))[0].split('_')[0]


def calculate_sample_size(
        population: int,
        alpha_level=ALPHA_LEVEL,
        accepted_margin_of_error=MARGIN_OF_ERROR,
):
    """Given alpha_level (which is equal to 1-confidence interval),
    estimated standard deviation, accepted margin of error
    and population size, return the required sample size."""
    t_val = norm.ppf(1 - alpha_level / 2)  # for two-tail test
    p = 0.5
    sample_size = (t_val * p / accepted_margin_of_error)**2
    if sample_size > 0.05 * population:
        sample_size = sample_size / (1 + sample_size / population)
    return math.ceil(sample_size)


def generate_sentiment_counts_dataframe(inpath: str):
    """Given a prediction file, return a dataframe containing the sentiment
    counts."""
    df = read_predictions(inpath)
    sentiment_counts = df.Predicted.value_counts().to_frame()
    sentiment_counts.name = generate_dfname_from_filename(inpath)
    return sentiment_counts


def generate_sentiment_counts_multiple_files(prediction_files: list):
    """Given a list of prediction files, generate a dataframe containing
    sentiment counts from all files."""
    data = []
    for f in prediction_files:
        data.append(generate_sentiment_counts_dataframe(f))
    concat_data = pd.concat(data, axis=1)
    concat_data.columns = [d.name for d in data]
    concat_data['row_sum'] = concat_data.sum(axis=1)
    col_sum = pd.Series(concat_data.sum(axis=0), name='col_sum')
    return concat_data.append(col_sum)


def chi2_test_independence(prediction_files: list, confidence_level: float):
    """Given a list of prediction files and a required confidence level,
    return whether the sentiment probability is independent on which prediction
    file it comes from.

    Returns True if the sentiment probability is independent of source."""
    df = generate_sentiment_counts_multiple_files(prediction_files)
    observed = df[:-1].drop(columns='row_sum')
    expected = np.outer(df['row_sum'][:-1],
                        df.loc['col_sum'][:-1]) / df.loc['col_sum']['row_sum']
    expected = pd.DataFrame(expected)
    expected.columns = df.columns[:-1]
    expected.index = df.index[:-1]
    chi2_stats = ((observed - expected)**2 / expected).sum().sum()
    degs_of_freedom = len(observed) * len(observed.iloc[0])
    critical_value = chi2.ppf(q=confidence_level, df=degs_of_freedom)
    p_value = 1 - chi2.cdf(x=chi2_stats, df=degs_of_freedom)
    LOGGER.info(
        f"chi2_stats = {chi2_stats}, critical_value = {critical_value}, p_value = {p_value:.10f}"
    )
    return p_value > (1 - confidence_level)


def calculate_margin_of_error(p, n, N, t):
    """Use normal approximation to estimate the margin of
    error for a variable.
    
    Args:
        - p = estimated probability of this variable
        - n = sample size
        - N = population size
        - t = normal deviate corresponding to a chosen
          confidence level
    """
    f = n / N
    variance = p * (1 - p) / (n - 1)
    return t * ((1 - f) * variance)**.5 + 1 / (2 * n)


def construct_stats_dataframe_from_predictions_csv(inpath: str,
                                                   alpha_level: float,
                                                   dfname: str,
                                                   population=math.inf):
    """Construct a pandas dataframe from a prediction csv file.

    The returned dataframe contains probability that a given document in the
    prediction negative, positive, and neutral sentiments, as well as the
    corresponding standard errors. The size of standard error is dependent on
    zvalue. The returned dataframe will receive dfname as its name.
    """
    predictions = read_predictions(inpath)
    n = predictions.shape[0]
    t_val = norm.ppf(1 - alpha_level / 2)  # for two-tail test

    sentiment_counts = predictions.Predicted.value_counts().to_frame()
    sentiment_prob = sentiment_counts.Predicted / n
    margin_of_error = calculate_margin_of_error(sentiment_prob, n, population,
                                                t_val)
    #previous margin of error calculation:
    #((sentiment_prob * (1 - sentiment_prob) / n)**.5) * t_val

    stats_data = {
        'sentiment_prob': sentiment_prob,
        'margin_of_error': margin_of_error
    }
    stats = pd.DataFrame(data=stats_data).sort_index(axis='index')
    stats.name = dfname
    log = f'{dfname:23}'
    for i in [NEGATIVE, NEUTRAL, POSITIVE]:
        log += f'${stats_data["sentiment_prob"][i]:.4f}\pm{stats_data["margin_of_error"][i]:.4f}$   '
    LOGGER.info(log)
    return stats


def plot_sentiment_probability(dataframes: list,
                               plotname: str,
                               width=0.5,
                               fill=True,
                               hatches=False):
    """Given a list of dataframes calculated using
    stats.construct_stats_dataframe_from_predictions_csv
    method, plot the sentiment probabilities and margin of
    errors of these dataframes.

    Hatches can consist of the following symbols:
        / \ | - + x o 0 . *
    """
    hatch_list = ['0', '..', '/', 'oo', '*', '+', '\\', '--', '||']
    distance_between_classes = width * 1.2
    fig = plt.figure(figsize=(15, 10))
    ax = fig.add_axes([.1, .2, .8, .6])
    indices = dataframes[0].index
    num_dataframes = len(dataframes)
    bar_width = (width / num_dataframes) * 0.9
    colormap = plt.get_cmap('Set2')
    matplotlib.rcParams.update({
        'font.size': 18,
        'hatch.color': 'grey',
        'legend.fontsize': 'small',
    })
    for i, d in enumerate(dataframes):
        if not hatches or fill:
            ax.bar(
                distance_between_classes * indices +
                i * width / num_dataframes,
                d.sentiment_prob,
                width=bar_width,
                yerr=d.margin_of_error,
                label=d.name,
                hatch=hatch_list[i % len(hatch_list)],
                fill=fill,
                color=colormap(i / num_dataframes),
            )
        else:
            ax.bar(
                distance_between_classes * indices +
                i * width / num_dataframes,
                d.sentiment_prob,
                width=bar_width,
                yerr=d.margin_of_error,
                label=d.name,
                fill=fill,
                color=colormap(i / num_dataframes),
            )
    ax.set_ylabel('Probability', fontsize='15')
    ax.set_xticks([
        distance_between_classes * i +
        (num_dataframes - 1) * width / num_dataframes / 2 for i in indices
    ])
    ax.set_ylim(ymin=0, ymax=.9)
    ax.set_xticklabels(['negative', 'neutral', 'positive'], fontsize=18)
    ax.legend(
        bbox_to_anchor=[.5, -.3],
        loc='lower center',
        borderaxespad=0.5,
        ncol=3)
    plt.savefig(f'{plotname}.svg')


def plot_predictions(predictions: list,
                     alpha_level: float,
                     plotname: str,
                     width=0.5,
                     fill=True,
                     hatches=False,
                     population=None):
    """Given a list of prediction files, and a dictionary of populations,
    calculate sentiment probabilities and save a resulting plot under
    plotname."""
    dataframes = []
    for d in predictions:
        dfname = generate_dfname_from_filename(d)
        if population:
            pop = population[dfname]
        else:
            pop = math.inf
        stats_df = construct_stats_dataframe_from_predictions_csv(
            d, alpha_level, dfname, pop)
        dataframes.append(stats_df)

    plot_sentiment_probability(
        dataframes, plotname, width, fill=fill, hatches=hatches)
